{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint\n",
    "from sklearn.pipeline import Pipeline\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import itertools\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix, accuracy_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "device = torch.device('cuda')\n",
    "\n",
    "from utils import predict_on_batch, measure_accuracy\n",
    "from dataset import Dataset, EmbDataset, pad_tensor, Padder\n",
    "from train import train, train_multitask\n",
    "from recformer import RecFormer, MiltitaskRecFormer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikit\\miniconda3\\envs\\rpz\\lib\\site-packages\\sklearn\\base.py:324: UserWarning: Trying to unpickle estimator LinearSVC from version 0.24.2 when using version 1.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\nikit\\miniconda3\\envs\\rpz\\lib\\site-packages\\sklearn\\base.py:324: UserWarning: Trying to unpickle estimator _SigmoidCalibration from version 0.24.2 when using version 1.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\nikit\\miniconda3\\envs\\rpz\\lib\\site-packages\\sklearn\\base.py:324: UserWarning: Trying to unpickle estimator CalibratedClassifierCV from version 0.24.2 when using version 1.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "LoadedSVC = pickle.load(open('LinearSVCModel.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ToRecipeString(RecipeIDs: list):\n",
    "    # Removes 0s padded to the recipe in document read\n",
    "    RecipeList = []\n",
    "    for i, IDs in enumerate(RecipeIDs):\n",
    "        R_l = [str(int(v)) for v in IDs if v !=0]\n",
    "        RecipeList.append(R_l) \n",
    "    \n",
    "    # combines IDs in Recipe as one string\n",
    "    RecipeStrings = []\n",
    "    for r in RecipeList:\n",
    "        RecipeStrings.append(' '.join(r))\n",
    "        \n",
    "    return RecipeStrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ingredient_name = pd.read_csv('node_ingredient.txt', engine='python', delimiter=',,', header=None)\n",
    "df = pd.read_csv('train.csv', engine= 'python', sep='\\,',  names=list(range(60)))\n",
    "\n",
    "# Validation data\n",
    "VLabels = pd.read_csv('validation_classification_answer.csv', engine='python', delimiter=',,', header=None)\n",
    "VRecipe = pd.read_csv('validation_classification_question.csv', engine= 'python', sep='\\,',  names=list(range(59)), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'brazilian': 0, 'british': 1, 'cajun_creole': 2, 'chinese': 3, 'filipino': 4, 'french': 5, 'greek': 6, 'indian': 7, 'irish': 8, 'italian': 9, 'jamaican': 10, 'japanese': 11, 'korean': 12, 'mexican': 13, 'moroccan': 14, 'russian': 15, 'southern_us': 16, 'spanish': 17, 'thai': 18, 'vietnamese': 19}\n"
     ]
    }
   ],
   "source": [
    "cuisine_vocab = {cuisine: id for id, cuisine in enumerate(np.unique(VLabels))}\n",
    "#cuisine_vocab = {'greek': 0, 'filipino': 1, 'indian': 2, 'jamaican': 3, 'spanish': 4, 'italian': 5, 'mexican': 6, 'vietnamese': 7, 'thai': 8, 'southern_us': 9, 'chinese': 10, 'cajun_creole': 11, 'brazilian': 12, 'french': 13, 'japanese': 14, 'irish': 15, 'moroccan': 16, 'korean': 17, 'british': 18, 'russian': 19}\n",
    "id_to_cus = {y: x for x, y in cuisine_vocab.items()}\n",
    "print(cuisine_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IngredientList = (np.squeeze(ingredient_name.values)).tolist()\n",
    "df1 = df.fillna(0)\n",
    "df_2 = df1.values.tolist()\n",
    "\n",
    "# validation data\n",
    "ValReci = VRecipe.fillna(0)\n",
    "VRecipes = ValReci.values.tolist()\n",
    "VLabels = (np.squeeze(VLabels.values)).tolist()\n",
    "label_ids = [cuisine_vocab[label] for label in VLabels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainRecipeList = []\n",
    "Cuisines = []\n",
    "for i, val in enumerate(df_2):\n",
    "    R_l = [v for v in val if v !=0]\n",
    "    TrainRecipeList.append(R_l[:-1]) \n",
    "    Cuisines.append(R_l[-1])\n",
    "\n",
    "RecipeStrings = ToRecipeString(TrainRecipeList)\n",
    "ValRecipeStrings = ToRecipeString(VRecipes)\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 1))\n",
    "matrix_train=vectorizer.fit_transform(RecipeStrings)\n",
    "matrix_val = vectorizer.transform(ValRecipeStrings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7848, 20)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probs = LoadedSVC.predict_proba(matrix_val)\n",
    "pred_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7804536187563711"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(VLabels, [id_to_cus[id] for id in np.argmax(pred_probs, axis=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogReg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikit\\miniconda3\\envs\\rpz\\lib\\site-packages\\sklearn\\base.py:324: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.2 when using version 1.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "loadedLogR = pickle.load(open('LogRegressionModel.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7848, 20)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probs_lr = loadedLogR.predict_proba(matrix_val)\n",
    "pred_probs_lr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RecFormer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_vocab_recformer = {'greek': 0, 'filipino': 1, 'indian': 2, 'jamaican': 3, 'spanish': 4, 'italian': 5, 'mexican': 6, 'vietnamese': 7, 'thai': 8, 'southern_us': 9, 'chinese': 10, 'cajun_creole': 11, 'brazilian': 12, 'french': 13, 'japanese': 14, 'irish': 15, 'moroccan': 16, 'korean': 17, 'british': 18, 'russian': 19}\n",
    "id_to_cus_recformer = {y: x for x, y in cuisine_vocab_recformer.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('validation_classification_question.csv', engine= 'python', sep='\\,',  names=list(range(60)))\n",
    "df1 = df.fillna(0)\n",
    "val_x = df1.values.tolist()\n",
    "\n",
    "df = pd.read_csv('validation_classification_answer.csv', engine= 'python', sep='\\,',  names=list(range(60)))\n",
    "df1 = df.fillna(0)\n",
    "val_y = df1.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7848 7848\n"
     ]
    }
   ],
   "source": [
    "val_ingredients_c = []\n",
    "val_labels_c = []\n",
    "\n",
    "for i in range(len(val_x)):\n",
    "  R_l = [v for v in val_x[i] if v !=0]\n",
    "  val_ingredients_c.append(list(map(int, R_l[:-1]))) \n",
    "  val_labels_c.append(cuisine_vocab[val_y[i][0]])\n",
    "\n",
    "print(len(val_ingredients_c), len(val_labels_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "padder = Padder(dim=1, pad_symbol=-1)\n",
    "validation_dataset_cuisine = Dataset(val_ingredients_c, val_labels_c)\n",
    "validation_loader_cuisine = DataLoader(dataset=validation_dataset_cuisine, batch_size=1024, collate_fn = padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MiltitaskRecFormer(num_tokens=6714, num_labels=20, dim_model=128, num_heads=4, num_encoder_layers=3, num_decoder_layers=1, dropout_p=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"weights/RecFormer_multitask.pth\"))\n",
    "model.to(device)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7848, 20)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "pred_probs_recformer = []\n",
    "with torch.no_grad():\n",
    "    for batch in validation_loader_cuisine:\n",
    "        preds = predict_on_batch(model, batch, \"cuisine\")\n",
    "        pred_probs_recformer.extend(preds.tolist())\n",
    "pred_probs_recformer = np.array(pred_probs_recformer)\n",
    "print(pred_probs_recformer.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.761085626911315"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(VLabels, [id_to_cus_recformer[id] for id in np.argmax(pred_probs_recformer, axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 18, 11, 10, 1, 13, 0, 2, 15, 5, 3, 14, 17, 6, 16, 19, 9, 4, 8, 7]\n"
     ]
    }
   ],
   "source": [
    "dim_order = []\n",
    "for key, value in cuisine_vocab.items():\n",
    "    dim_order.append(cuisine_vocab_recformer[key])\n",
    "print(dim_order)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.761085626911315"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(VLabels, [id_to_cus[id] for id in np.argmax(pred_probs_recformer[:, dim_order], axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7872069317023446 0.39\n"
     ]
    }
   ],
   "source": [
    "w_max = 0\n",
    "acc_max = 0\n",
    "for w in np.linspace(0,1,101):\n",
    "    pred_probs_stack = w * pred_probs_recformer[:, dim_order] + (1-w) * pred_probs\n",
    "    acc = accuracy_score(VLabels, [id_to_cus[id] for id in np.argmax(pred_probs_stack, axis=1)])\n",
    "    if acc > acc_max:\n",
    "        acc_max = acc\n",
    "        w_max = w\n",
    "print(acc_max, w_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7872069317023446"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probs_stack = w_max * pred_probs_recformer[:, dim_order] + (1 - w_max) * pred_probs\n",
    "accuracy_score(VLabels, [id_to_cus[id] for id in np.argmax(pred_probs_stack, axis=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikit\\miniconda3\\envs\\rpz\\lib\\site-packages\\sklearn\\base.py:324: UserWarning: Trying to unpickle estimator LinearSVC from version 0.24.2 when using version 1.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\nikit\\miniconda3\\envs\\rpz\\lib\\site-packages\\sklearn\\base.py:324: UserWarning: Trying to unpickle estimator _SigmoidCalibration from version 0.24.2 when using version 1.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\nikit\\miniconda3\\envs\\rpz\\lib\\site-packages\\sklearn\\base.py:324: UserWarning: Trying to unpickle estimator CalibratedClassifierCV from version 0.24.2 when using version 1.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "loadedSVC_completion = pickle.load(open('LinearSVCModel_completion.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "VCAns = pd.read_csv('validation_completion_answer.csv', engine='python', delimiter=',,', header=None)\n",
    "VTrain = pd.read_csv('validation_completion_question.csv', engine= 'python', sep='\\,',  names=list(range(58)), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253453 253453\n"
     ]
    }
   ],
   "source": [
    "# completion task training data creation\n",
    "CompData = []\n",
    "CompLabel = []\n",
    "for i, inda in enumerate(TrainRecipeList):\n",
    "    for a in range(len(inda)):\n",
    "        compy = inda.copy()\n",
    "        label = compy.pop(a)\n",
    "        \n",
    "        CompData.append(compy)\n",
    "        CompLabel.append(label)\n",
    "print(len(CompData), len(CompLabel))\n",
    "TCompStrings = ToRecipeString(CompData)\n",
    "VTrain = VTrain.fillna(0)\n",
    "VCompData = VTrain.values.tolist()\n",
    "VCompStrings = ToRecipeString(VCompData)\n",
    "def ConvertLabels(LabelIDs):\n",
    "    # Conversion of IDs to ingredients\n",
    "    LReci = [str(int(v)) for v in LabelIDs]\n",
    "    return LReci\n",
    "VCAnsL = (np.squeeze(VCAns.values)).tolist() \n",
    "VCompLabels = ConvertLabels(VCAnsL)\n",
    "TCompLabels = ConvertLabels(CompLabel)\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 1))\n",
    "\n",
    "# tokenize and build vocab\n",
    "matrix_train = vectorizer.fit_transform(TCompStrings)\n",
    "matrix_val = vectorizer.transform(VCompStrings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7848, 5858)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probs_completion_svc = loadedSVC_completion.predict_proba(matrix_val)\n",
    "pred_probs_completion_svc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1365953109072375"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(VCompLabels, loadedSVC_completion.classes_[np.argmax(pred_probs_completion_svc, axis=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RecFormer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_map = [int(i) for i in loadedSVC_completion.classes_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7848 7848\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('validation_completion_question.csv', engine= 'python', sep='\\,',  names=list(range(60)))\n",
    "df1 = df.fillna(0)\n",
    "val_x = df1.values.tolist()\n",
    "\n",
    "df = pd.read_csv('validation_completion_answer.csv', engine= 'python', sep='\\,',  names=list(range(60)))\n",
    "df1 = df.fillna(0)\n",
    "val_y = df1.values.tolist()\n",
    "\n",
    "print(len(val_x), len(val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7848 7848\n"
     ]
    }
   ],
   "source": [
    "val_ingredients = []\n",
    "val_labels = []\n",
    "\n",
    "for i in range(len(val_x)):\n",
    "  R_l = [v for v in val_x[i] if v !=0]\n",
    "  val_ingredients.append(list(map(int, R_l[:-1]))) \n",
    "  val_labels.append(int(val_y[i][0]))\n",
    "\n",
    "print(len(val_ingredients), len(val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset_ingredients = Dataset(val_ingredients, val_labels)\n",
    "validation_loader_ingredients = DataLoader(dataset=validation_dataset_ingredients, batch_size=64, collate_fn = padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7848, 6714)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "completion_preds = []\n",
    "with torch.no_grad():\n",
    "    for batch in validation_loader_ingredients:\n",
    "        preds = predict_on_batch(model, batch, \"ingredients\")\n",
    "        completion_preds.extend(preds.tolist())\n",
    "completion_preds = np.array(completion_preds)\n",
    "print(completion_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12436289500509684\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(VCompLabels, loadedSVC_completion.classes_[np.argmax(completion_preds[:,svc_map], axis=1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14475025484199797 0.26\n"
     ]
    }
   ],
   "source": [
    "w_max = 0\n",
    "acc_max = 0\n",
    "completion_preds_mapped = completion_preds[:,svc_map]\n",
    "for w in np.linspace(0,1,101):\n",
    "    pred_probs_stack = w * completion_preds_mapped + (1-w) * pred_probs_completion_svc\n",
    "    acc = accuracy_score(VCompLabels, loadedSVC_completion.classes_[np.argmax(pred_probs_stack, axis=1)])\n",
    "    if acc > acc_max:\n",
    "        acc_max = acc\n",
    "        w_max = w\n",
    "print(acc_max, w_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14475025484199797"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probs_stack = w_max * completion_preds_mapped + (1-w_max) * pred_probs_completion_svc\n",
    "accuracy_score(VCompLabels, loadedSVC_completion.classes_[np.argmax(pred_probs_stack, axis=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test predictions generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
