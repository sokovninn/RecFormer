{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint\n",
    "from sklearn.pipeline import Pipeline\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import itertools\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix, accuracy_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikit\\miniconda3\\envs\\rpz\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "device = torch.device('cuda')\n",
    "\n",
    "from recformer.utils import predict_on_batch, measure_accuracy\n",
    "from recformer.dataset import Dataset, EmbDataset, pad_tensor, Padder\n",
    "from recformer.train import train, train_multitask\n",
    "from recformer.recformer import RecFormer, MiltitaskRecFormer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikit\\miniconda3\\envs\\rpz\\lib\\site-packages\\sklearn\\base.py:324: UserWarning: Trying to unpickle estimator LinearSVC from version 0.24.2 when using version 1.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\nikit\\miniconda3\\envs\\rpz\\lib\\site-packages\\sklearn\\base.py:324: UserWarning: Trying to unpickle estimator _SigmoidCalibration from version 0.24.2 when using version 1.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\nikit\\miniconda3\\envs\\rpz\\lib\\site-packages\\sklearn\\base.py:324: UserWarning: Trying to unpickle estimator CalibratedClassifierCV from version 0.24.2 when using version 1.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "LoadedSVC = pickle.load(open('baselines/LinearSVCModel.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ToRecipeString(RecipeIDs: list):\n",
    "    # Removes 0s padded to the recipe in document read\n",
    "    RecipeList = []\n",
    "    for i, IDs in enumerate(RecipeIDs):\n",
    "        R_l = [str(int(v)) for v in IDs if v !=0]\n",
    "        RecipeList.append(R_l) \n",
    "    \n",
    "    # combines IDs in Recipe as one string\n",
    "    RecipeStrings = []\n",
    "    for r in RecipeList:\n",
    "        RecipeStrings.append(' '.join(r))\n",
    "        \n",
    "    return RecipeStrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ingredient_name = pd.read_csv('node_ingredient.txt', engine='python', delimiter=',,', header=None)\n",
    "df = pd.read_csv('train.csv', engine= 'python', sep='\\,',  names=list(range(60)))\n",
    "\n",
    "# Validation data\n",
    "VLabels = pd.read_csv('validation_classification_answer.csv', engine='python', delimiter=',,', header=None)\n",
    "VRecipe = pd.read_csv('validation_classification_question.csv', engine= 'python', sep='\\,',  names=list(range(59)), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'brazilian': 0, 'british': 1, 'cajun_creole': 2, 'chinese': 3, 'filipino': 4, 'french': 5, 'greek': 6, 'indian': 7, 'irish': 8, 'italian': 9, 'jamaican': 10, 'japanese': 11, 'korean': 12, 'mexican': 13, 'moroccan': 14, 'russian': 15, 'southern_us': 16, 'spanish': 17, 'thai': 18, 'vietnamese': 19}\n"
     ]
    }
   ],
   "source": [
    "cuisine_vocab = {cuisine: id for id, cuisine in enumerate(np.unique(VLabels))}\n",
    "#cuisine_vocab = {'greek': 0, 'filipino': 1, 'indian': 2, 'jamaican': 3, 'spanish': 4, 'italian': 5, 'mexican': 6, 'vietnamese': 7, 'thai': 8, 'southern_us': 9, 'chinese': 10, 'cajun_creole': 11, 'brazilian': 12, 'french': 13, 'japanese': 14, 'irish': 15, 'moroccan': 16, 'korean': 17, 'british': 18, 'russian': 19}\n",
    "id_to_cus = {y: x for x, y in cuisine_vocab.items()}\n",
    "print(cuisine_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IngredientList = (np.squeeze(ingredient_name.values)).tolist()\n",
    "df1 = df.fillna(0)\n",
    "df_2 = df1.values.tolist()\n",
    "\n",
    "# validation data\n",
    "ValReci = VRecipe.fillna(0)\n",
    "VRecipes = ValReci.values.tolist()\n",
    "VLabels = (np.squeeze(VLabels.values)).tolist()\n",
    "label_ids = [cuisine_vocab[label] for label in VLabels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainRecipeList = []\n",
    "Cuisines = []\n",
    "for i, val in enumerate(df_2):\n",
    "    R_l = [v for v in val if v !=0]\n",
    "    TrainRecipeList.append(R_l[:-1]) \n",
    "    Cuisines.append(R_l[-1])\n",
    "\n",
    "RecipeStrings = ToRecipeString(TrainRecipeList)\n",
    "ValRecipeStrings = ToRecipeString(VRecipes)\n",
    "vectorizer_classification = TfidfVectorizer(ngram_range=(1, 1))\n",
    "matrix_train=vectorizer_classification.fit_transform(RecipeStrings)\n",
    "matrix_val = vectorizer_classification.transform(ValRecipeStrings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7848, 20)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probs = LoadedSVC.predict_proba(matrix_val)\n",
    "pred_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7804536187563711"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(VLabels, [id_to_cus[id] for id in np.argmax(pred_probs, axis=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogReg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikit\\miniconda3\\envs\\rpz\\lib\\site-packages\\sklearn\\base.py:324: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.2 when using version 1.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "loadedLogR = pickle.load(open('baselines/LogRegressionModel.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7848, 20)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probs_lr = loadedLogR.predict_proba(matrix_val)\n",
    "pred_probs_lr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RecFormer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_vocab_recformer = {'greek': 0, 'filipino': 1, 'indian': 2, 'jamaican': 3, 'spanish': 4, 'italian': 5, 'mexican': 6, 'vietnamese': 7, 'thai': 8, 'southern_us': 9, 'chinese': 10, 'cajun_creole': 11, 'brazilian': 12, 'french': 13, 'japanese': 14, 'irish': 15, 'moroccan': 16, 'korean': 17, 'british': 18, 'russian': 19}\n",
    "id_to_cus_recformer = {y: x for x, y in cuisine_vocab_recformer.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('validation_classification_question.csv', engine= 'python', sep='\\,',  names=list(range(60)))\n",
    "df1 = df.fillna(0)\n",
    "val_x = df1.values.tolist()\n",
    "\n",
    "df = pd.read_csv('validation_classification_answer.csv', engine= 'python', sep='\\,',  names=list(range(60)))\n",
    "df1 = df.fillna(0)\n",
    "val_y = df1.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7848 7848\n"
     ]
    }
   ],
   "source": [
    "val_ingredients_c = []\n",
    "val_labels_c = []\n",
    "\n",
    "for i in range(len(val_x)):\n",
    "  R_l = [v for v in val_x[i] if v !=0]\n",
    "  val_ingredients_c.append(list(map(int, R_l[:-1]))) \n",
    "  val_labels_c.append(cuisine_vocab[val_y[i][0]])\n",
    "\n",
    "print(len(val_ingredients_c), len(val_labels_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "emb_length = 300\n",
    "glove_vocab = {}\n",
    "with open('glove.6B/glove.6B.{}d.txt'.format(emb_length), encoding='utf-8') as f:\n",
    "  for line in f:\n",
    "      values = line.split()\n",
    "      word = values[0]\n",
    "      coefs = np.asarray(values[1:], dtype='float32')\n",
    "      glove_vocab[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_embedding = torch.zeros(emb_length)\n",
    "UNK_embedding = np.mean(list(glove_vocab.values()), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6714\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_fwf('node_ingredient.csv', header=None)\n",
    "node_ingredient = df[0].values.tolist()\n",
    "print(len(node_ingredient))\n",
    "ing_id_to_str = {i: ing for i,ing in enumerate(node_ingredient)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "padder = Padder(dim=0, pad_symbol=PAD_embedding)\n",
    "\n",
    "validation_dataset_cuisine = EmbDataset(val_ingredients_c, val_labels_c, glove_vocab, UNK_embedding, ing_id_to_str)\n",
    "validation_loader_cuisine = DataLoader(dataset=validation_dataset_cuisine, batch_size=64, collate_fn = padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padder = Padder(dim=1, pad_symbol=-1)\n",
    "# validation_dataset_cuisine = Dataset(val_ingredients_c, val_labels_c)\n",
    "# validation_loader_cuisine = DataLoader(dataset=validation_dataset_cuisine, batch_size=1024, collate_fn = padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MiltitaskRecFormer(num_tokens=6714, num_labels=20, dim_model=300, num_heads=4, num_encoder_layers=3, num_decoder_layers=1, dropout_p=0.3, use_pretrained_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"weights/RecFormer_multitask_emb.pth\"))\n",
    "model.to(device)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7848, 20)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "pred_probs_recformer = []\n",
    "with torch.no_grad():\n",
    "    for batch in validation_loader_cuisine:\n",
    "        preds = predict_on_batch(model, batch, \"cuisine\")\n",
    "        pred_probs_recformer.extend(preds.tolist())\n",
    "pred_probs_recformer = np.array(pred_probs_recformer)\n",
    "print(pred_probs_recformer.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7663098878695209"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(VLabels, [id_to_cus_recformer[id] for id in np.argmax(pred_probs_recformer, axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 18, 11, 10, 1, 13, 0, 2, 15, 5, 3, 14, 17, 6, 16, 19, 9, 4, 8, 7]\n"
     ]
    }
   ],
   "source": [
    "dim_order = []\n",
    "for key, value in cuisine_vocab.items():\n",
    "    dim_order.append(cuisine_vocab_recformer[key])\n",
    "print(dim_order)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7663098878695209"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(VLabels, [id_to_cus[id] for id in np.argmax(pred_probs_recformer[:, dim_order], axis=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7920489296636085 0.31\n"
     ]
    }
   ],
   "source": [
    "w_max = 0\n",
    "acc_max = 0\n",
    "for w in np.linspace(0,1,101):\n",
    "    pred_probs_stack = w * pred_probs_recformer[:, dim_order] + (1-w) * pred_probs\n",
    "    acc = accuracy_score(VLabels, [id_to_cus[id] for id in np.argmax(pred_probs_stack, axis=1)])\n",
    "    if acc > acc_max:\n",
    "        acc_max = acc\n",
    "        w_max = w\n",
    "print(acc_max, w_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7920489296636085"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probs_stack = w_max * pred_probs_recformer[:, dim_order] + (1 - w_max) * pred_probs\n",
    "accuracy_score(VLabels, [id_to_cus[id] for id in np.argmax(pred_probs_stack, axis=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikit\\miniconda3\\envs\\rpz\\lib\\site-packages\\sklearn\\base.py:324: UserWarning: Trying to unpickle estimator LinearSVC from version 0.24.2 when using version 1.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\nikit\\miniconda3\\envs\\rpz\\lib\\site-packages\\sklearn\\base.py:324: UserWarning: Trying to unpickle estimator _SigmoidCalibration from version 0.24.2 when using version 1.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\nikit\\miniconda3\\envs\\rpz\\lib\\site-packages\\sklearn\\base.py:324: UserWarning: Trying to unpickle estimator CalibratedClassifierCV from version 0.24.2 when using version 1.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "loadedSVC_completion = pickle.load(open('baselines/LinearSVCModel_completion.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "VCAns = pd.read_csv('validation_completion_answer.csv', engine='python', delimiter=',,', header=None)\n",
    "VTrain = pd.read_csv('validation_completion_question.csv', engine= 'python', sep='\\,',  names=list(range(58)), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253453 253453\n"
     ]
    }
   ],
   "source": [
    "# completion task training data creation\n",
    "CompData = []\n",
    "CompLabel = []\n",
    "for i, inda in enumerate(TrainRecipeList):\n",
    "    for a in range(len(inda)):\n",
    "        compy = inda.copy()\n",
    "        label = compy.pop(a)\n",
    "        \n",
    "        CompData.append(compy)\n",
    "        CompLabel.append(label)\n",
    "print(len(CompData), len(CompLabel))\n",
    "TCompStrings = ToRecipeString(CompData)\n",
    "VTrain = VTrain.fillna(0)\n",
    "VCompData = VTrain.values.tolist()\n",
    "VCompStrings = ToRecipeString(VCompData)\n",
    "def ConvertLabels(LabelIDs):\n",
    "    # Conversion of IDs to ingredients\n",
    "    LReci = [str(int(v)) for v in LabelIDs]\n",
    "    return LReci\n",
    "VCAnsL = (np.squeeze(VCAns.values)).tolist() \n",
    "VCompLabels = ConvertLabels(VCAnsL)\n",
    "TCompLabels = ConvertLabels(CompLabel)\n",
    "vectorizer_completion = TfidfVectorizer(ngram_range=(1, 1))\n",
    "\n",
    "# tokenize and build vocab\n",
    "matrix_train = vectorizer_completion.fit_transform(TCompStrings)\n",
    "matrix_val = vectorizer_completion.transform(VCompStrings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7848, 5858)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probs_completion_svc = loadedSVC_completion.predict_proba(matrix_val)\n",
    "pred_probs_completion_svc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1365953109072375"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(VCompLabels, loadedSVC_completion.classes_[np.argmax(pred_probs_completion_svc, axis=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RecFormer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_map = [int(i) for i in loadedSVC_completion.classes_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7848 7848\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('validation_completion_question.csv', engine= 'python', sep='\\,',  names=list(range(60)))\n",
    "df1 = df.fillna(0)\n",
    "val_x = df1.values.tolist()\n",
    "\n",
    "df = pd.read_csv('validation_completion_answer.csv', engine= 'python', sep='\\,',  names=list(range(60)))\n",
    "df1 = df.fillna(0)\n",
    "val_y = df1.values.tolist()\n",
    "\n",
    "print(len(val_x), len(val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7848 7848\n"
     ]
    }
   ],
   "source": [
    "val_ingredients = []\n",
    "val_labels = []\n",
    "\n",
    "for i in range(len(val_x)):\n",
    "  R_l = [v for v in val_x[i] if v !=0]\n",
    "  val_ingredients.append(list(map(int, R_l[:-1]))) \n",
    "  val_labels.append(int(val_y[i][0]))\n",
    "\n",
    "print(len(val_ingredients), len(val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset_ingredients = EmbDataset(val_ingredients, val_labels, glove_vocab, UNK_embedding, ing_id_to_str)\n",
    "validation_loader_ingredients = DataLoader(dataset=validation_dataset_ingredients, batch_size=64, collate_fn = padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_dataset_ingredients = Dataset(val_ingredients, val_labels)\n",
    "# validation_loader_ingredients = DataLoader(dataset=validation_dataset_ingredients, batch_size=64, collate_fn = padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7848, 6714)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "completion_preds = []\n",
    "with torch.no_grad():\n",
    "    for batch in validation_loader_ingredients:\n",
    "        preds = predict_on_batch(model, batch, \"ingredients\")\n",
    "        completion_preds.extend(preds.tolist())\n",
    "completion_preds = np.array(completion_preds)\n",
    "print(completion_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12703873598369012\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(VCompLabels, loadedSVC_completion.classes_[np.argmax(completion_preds[:,svc_map], axis=1)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14742609582059124 0.2\n"
     ]
    }
   ],
   "source": [
    "w_max = 0\n",
    "acc_max = 0\n",
    "completion_preds_mapped = completion_preds[:,svc_map]\n",
    "for w in np.linspace(0,1,101):\n",
    "    pred_probs_stack = w * completion_preds_mapped + (1-w) * pred_probs_completion_svc\n",
    "    acc = accuracy_score(VCompLabels, loadedSVC_completion.classes_[np.argmax(pred_probs_stack, axis=1)])\n",
    "    if acc > acc_max:\n",
    "        acc_max = acc\n",
    "        w_max = w\n",
    "print(acc_max, w_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14742609582059124"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probs_stack = w_max * completion_preds_mapped + (1-w_max) * pred_probs_completion_svc\n",
    "accuracy_score(VCompLabels, loadedSVC_completion.classes_[np.argmax(pred_probs_stack, axis=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test predictions generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_classification = pd.read_csv('test_classification_question.csv', engine='python', sep='\\,',  names=list(range(65)), dtype='float32')\n",
    "test_data_classification = test_data_classification.fillna(0)\n",
    "test_data_classification = test_data_classification.values.tolist()\n",
    "\n",
    "\n",
    "test_data_strings_classification = ToRecipeString(test_data_classification)\n",
    "matrix_test_classification = vectorizer_classification.transform(test_data_strings_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3924, 20)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_probs_svc_classification = LoadedSVC.predict_proba(matrix_test_classification)\n",
    "test_probs_svc_classification.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RecFromer prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3924\n"
     ]
    }
   ],
   "source": [
    "test_ingredients_classification = []\n",
    "\n",
    "for i in range(len(test_data_classification)):\n",
    "  R_l = [v for v in test_data_classification[i] if v !=0]\n",
    "  test_ingredients_classification.append(list(map(int, R_l[:-1]))) \n",
    "\n",
    "print(len(test_ingredients_classification))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_classification = EmbDataset(test_ingredients_classification, np.zeros(len(test_ingredients_classification)), glove_vocab, UNK_embedding, ing_id_to_str)\n",
    "test_loader_classification = DataLoader(dataset=test_dataset_classification, batch_size=64, collate_fn = padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset_classification = Dataset(test_ingredients_classification, np.zeros(len(test_ingredients_classification)))\n",
    "# test_loader_classification = DataLoader(dataset=test_dataset_classification, batch_size=1024, collate_fn = padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3924, 20)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_probs_recformer_classification = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader_classification:\n",
    "        preds = predict_on_batch(model, batch, \"cuisine\")\n",
    "        test_probs_recformer_classification.extend(preds.tolist())\n",
    "test_probs_recformer_classification = np.array(test_probs_recformer_classification)\n",
    "print(test_probs_recformer_classification.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3924, 20)\n"
     ]
    }
   ],
   "source": [
    "w_cl = 0.31\n",
    "test_probs_stack_classification = w_cl * test_probs_recformer_classification[:, dim_order] + (1 - w_cl) * test_probs_svc_classification\n",
    "print(test_probs_stack_classification.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3924"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds_stack_classification = [id_to_cus[id] for id in np.argmax(test_probs_stack_classification, axis=1)]\n",
    "len(test_preds_stack_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(test_preds_stack_classification)\n",
    "df.to_csv('test_classification_answer.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_completion = pd.read_csv('test_completion_question.csv', engine='python', sep='\\,',  names=list(range(35)), dtype='float32')\n",
    "test_data_completion = test_data_completion.fillna(0)\n",
    "test_data_completion = test_data_completion.values.tolist()\n",
    "\n",
    "\n",
    "test_data_strings_completion = ToRecipeString(test_data_completion)\n",
    "matrix_test_completion = vectorizer_completion.transform(test_data_strings_completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3924, 5858)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_probs_svc_completion = loadedSVC_completion.predict_proba(matrix_test_completion)\n",
    "test_probs_svc_completion.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RecFormer prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3924\n"
     ]
    }
   ],
   "source": [
    "test_ingredients_completion = []\n",
    "\n",
    "for i in range(len(test_data_completion)):\n",
    "  R_l = [v for v in test_data_completion[i] if v !=0]\n",
    "  test_ingredients_completion.append(list(map(int, R_l[:-1]))) \n",
    "\n",
    "print(len(test_ingredients_completion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_completion = EmbDataset(test_ingredients_completion, np.zeros(len(test_ingredients_completion)), glove_vocab, UNK_embedding, ing_id_to_str)\n",
    "test_loader_completion = DataLoader(dataset=test_dataset_completion, batch_size=64, collate_fn = padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset_completion = Dataset(test_ingredients_completion, np.zeros(len(test_ingredients_completion)))\n",
    "# test_loader_completion = DataLoader(dataset=test_dataset_completion, batch_size=64, collate_fn = padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3924, 6714)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_probs_recformer_completion = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader_completion:\n",
    "        preds = predict_on_batch(model, batch, \"ingredients\")\n",
    "        test_probs_recformer_completion.extend(preds.tolist())\n",
    "test_probs_recformer_completion = np.array(test_probs_recformer_completion)\n",
    "print(test_probs_recformer_completion.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3924, 5858)\n"
     ]
    }
   ],
   "source": [
    "w_comp = 0.2\n",
    "test_probs_stack_completion = w_comp * test_probs_recformer_completion[:,svc_map] + (1-w_comp) * test_probs_svc_completion\n",
    "print(test_probs_stack_completion.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3924"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds_stack_completion = loadedSVC_completion.classes_[np.argmax(test_probs_stack_completion, axis=1)]\n",
    "len(test_preds_stack_completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(test_preds_stack_completion)\n",
    "df.to_csv('test_completion_answer.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
