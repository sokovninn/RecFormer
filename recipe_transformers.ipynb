{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OjH-sWUfbmX0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikit\\miniconda3\\envs\\rpz\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "device = torch.device('cuda')\n",
    "\n",
    "from recformer.utils import predict_on_batch, measure_accuracy\n",
    "from recformer.dataset import Dataset, EmbDataset, pad_tensor, Padder\n",
    "from recformer.train import train, train_multitask\n",
    "from recformer.recformer import RecFormer, MiltitaskRecFormer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ldjjic_ozgT",
    "outputId": "d374f679-c956-4587-e3c9-51a772c9aceb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23547"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_fwf('train.csv', header=None)\n",
    "data = df[0].str.split(',', expand=True).values.tolist()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9c4pTUPXsANA",
    "outputId": "5087515d-37b9-4b92-e185-1e30680307c6"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "cusine_counter = Counter()\n",
    "cusine_vocab = {}\n",
    "\n",
    "for recipe in data:\n",
    "  if None in recipe:\n",
    "    recipe_length = recipe.index(None) - 1\n",
    "  else:\n",
    "    recipe_length = len(recipe) - 1\n",
    "  cusine_counter[recipe[recipe_length]] +=1\n",
    "\n",
    "#print(cusine_counter)\n",
    "\n",
    "cusine_num = 0\n",
    "for k, v in cusine_counter.items():\n",
    "  if v > 100:\n",
    "    cusine_vocab[k] = cusine_num\n",
    "    cusine_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'greek': 0, 'filipino': 1, 'indian': 2, 'jamaican': 3, 'spanish': 4, 'italian': 5, 'mexican': 6, 'vietnamese': 7, 'thai': 8, 'southern_us': 9, 'chinese': 10, 'cajun_creole': 11, 'brazilian': 12, 'french': 13, 'japanese': 14, 'irish': 15, 'moroccan': 16, 'korean': 17, 'british': 18, 'russian': 19}\n"
     ]
    }
   ],
   "source": [
    "print(cusine_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3coIk46h2lc"
   },
   "source": [
    "Derrick's reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "RrVsynxXh2le"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv', engine= 'python', sep='\\,',  names=list(range(61)))\n",
    "df1 = df.fillna(0)\n",
    "df_2 = df1.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OwPN11k5h2lf"
   },
   "outputs": [],
   "source": [
    "# Separating the cuisines from the recipies \n",
    "train_ingredients = []\n",
    "train_labels = []\n",
    "for i, val in enumerate(df_2):\n",
    "    R_l = [v for v in val if v !=0]\n",
    "    train_ingredients.append(list(map(int, R_l[:-1]))) \n",
    "    train_labels.append(cusine_vocab[R_l[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZNONwX4yh2lh"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('validation_classification_question.csv', engine= 'python', sep='\\,',  names=list(range(60)))\n",
    "df1 = df.fillna(0)\n",
    "val_x = df1.values.tolist()\n",
    "\n",
    "df = pd.read_csv('validation_classification_answer.csv', engine= 'python', sep='\\,',  names=list(range(60)))\n",
    "df1 = df.fillna(0)\n",
    "val_y = df1.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iVgn4k-2h2li",
    "outputId": "c9b4619e-0eb2-42e7-c227-170350fdbc0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7848 7848\n"
     ]
    }
   ],
   "source": [
    "val_ingredients_c = []\n",
    "val_labels_c = []\n",
    "\n",
    "for i in range(len(val_x)):\n",
    "  R_l = [v for v in val_x[i] if v !=0]\n",
    "  val_ingredients_c.append(list(map(int, R_l[:-1]))) \n",
    "  val_labels_c.append(cusine_vocab[val_y[i][0]])\n",
    "\n",
    "print(len(val_ingredients_c), len(val_labels_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "b5wlkqmch2ll"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 32\n",
    "\n",
    "num_labels = len(cusine_vocab)\n",
    "num_tokens = 6714\n",
    "dim_model = 128\n",
    "num_heads = 4\n",
    "num_encoder_layers = 3\n",
    "num_decoder_layers = 1\n",
    "dropout_p = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "EIdBO83d2PCS"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "padder = Padder(dim=1, pad_symbol=-1)\n",
    "train_dataset = Dataset(train_ingredients, train_labels)\n",
    "validation_dataset = Dataset(val_ingredients_c, val_labels_c)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, collate_fn = padder, shuffle=True)\n",
    "validation_loader = DataLoader(dataset=validation_dataset, batch_size=batch_size, collate_fn = padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "lhQbmGHr2nqY"
   },
   "outputs": [],
   "source": [
    "model = RecFormer(num_tokens, num_labels, dim_model, num_heads, num_encoder_layers, num_decoder_layers, dropout_p)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "id": "MvAx6Z6H4VfH",
    "outputId": "8e175f58-957c-4e4c-bf34-22ffd2d68820"
   },
   "outputs": [],
   "source": [
    "train(model, criterion, optimizer, train_loader, validation_loader, epochs, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), \"RecFormer_classification.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sa5JV1GA-_AY",
    "outputId": "6b836e02-5efc-4509-d330-8b089fd889f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9040, device='cuda:0')\n",
      "tensor(0.7429, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"weights/RecFormer_classification.pth\"))\n",
    "model.to(device)\n",
    "print(measure_accuracy(model, train_loader))\n",
    "print(measure_accuracy(model, validation_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NuOEsJhjFzPm"
   },
   "source": [
    "# Completion task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WtiOUBPXF24U",
    "outputId": "6ce04b84-d442-4176-f659-d94cbab16bb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253453 253453\n"
     ]
    }
   ],
   "source": [
    "completion_data = []\n",
    "completion_labels = []\n",
    "\n",
    "for recipe in train_ingredients:\n",
    "  ingredients_num = len(recipe)\n",
    "  for i in range(ingredients_num):\n",
    "    incomplete_recipe = recipe[:ingredients_num].copy()\n",
    "    missing_ingredient = incomplete_recipe.pop(i)\n",
    "\n",
    "    completion_data.append(incomplete_recipe)\n",
    "    completion_labels.append(missing_ingredient)\n",
    "\n",
    "print(len(completion_data), len(completion_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B73AY0aeh2lp",
    "outputId": "c9a986ce-f8aa-4188-8ef6-1f62028e44d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7848 7848\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('validation_completion_question.csv', engine= 'python', sep='\\,',  names=list(range(60)))\n",
    "df1 = df.fillna(0)\n",
    "val_x = df1.values.tolist()\n",
    "\n",
    "df = pd.read_csv('validation_completion_answer.csv', engine= 'python', sep='\\,',  names=list(range(60)))\n",
    "df1 = df.fillna(0)\n",
    "val_y = df1.values.tolist()\n",
    "\n",
    "print(len(val_x), len(val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UT6s9YVZh2lp",
    "outputId": "93f94c5e-abfd-419c-9bfc-a3c0b2481083"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7848 7848\n"
     ]
    }
   ],
   "source": [
    "val_ingredients = []\n",
    "val_labels = []\n",
    "\n",
    "for i in range(len(val_x)):\n",
    "  R_l = [v for v in val_x[i] if v !=0]\n",
    "  val_ingredients.append(list(map(int, R_l[:-1]))) \n",
    "  val_labels.append(int(val_y[i][0]))\n",
    "\n",
    "print(len(val_ingredients), len(val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "DXViAMNlKJXU"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "padder = Padder(dim=1, pad_symbol=-1)\n",
    "train_dataset = Dataset(completion_data, completion_labels)\n",
    "validation_dataset = Dataset(val_ingredients, val_labels)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, collate_fn = padder, shuffle=True)\n",
    "validation_loader = DataLoader(dataset=validation_dataset, batch_size=batch_size, collate_fn = padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "qN061SvcLqWg"
   },
   "outputs": [],
   "source": [
    "model = RecFormer(num_tokens, num_tokens, dim_model, num_heads, num_encoder_layers, num_decoder_layers, dropout_p)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j-KDPWK0LtVg",
    "outputId": "369e1050-a6a2-4928-ffaa-172215c880c1"
   },
   "outputs": [],
   "source": [
    "train(model, criterion, optimizer, train_loader, validation_loader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), \"RecFormer_completion.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7kg7YAPmMZko",
    "outputId": "151b0bff-674c-4be2-df64-bf3c0147e8bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1541, device='cuda:0')\n",
      "tensor(0.1138, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"weights/RecFormer_completion.pth\"))\n",
    "model.to(device)\n",
    "\n",
    "print(measure_accuracy(model, train_loader))\n",
    "print(measure_accuracy(model, validation_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8AHRk7sQIRP"
   },
   "source": [
    "# Mutlti-task experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S58GJgNTh2lr",
    "outputId": "bf35013c-15ab-449e-d87e-bcae281de7cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253453 253453\n"
     ]
    }
   ],
   "source": [
    "multitask_data = []\n",
    "multitask_labels = []\n",
    "\n",
    "\n",
    "for recipe, cusine in zip(train_ingredients, train_labels):\n",
    "  ingredients_num = len(recipe)\n",
    "  for i in range(ingredients_num):\n",
    "    incomplete_recipe = recipe[:ingredients_num].copy()\n",
    "    missing_ingredient = incomplete_recipe.pop(i)\n",
    "\n",
    "    multitask_data.append(incomplete_recipe)\n",
    "    multitask_labels.append([cusine, missing_ingredient])\n",
    "    \n",
    "print(len(multitask_data), len(multitask_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "TVGKTCr8h2ls"
   },
   "outputs": [],
   "source": [
    "padder = Padder(dim=1, pad_symbol=-1)\n",
    "train_dataset = Dataset(multitask_data, multitask_labels)\n",
    "validation_dataset_cuisine = Dataset(val_ingredients_c, val_labels_c)\n",
    "validation_dataset_ingredients = Dataset(val_ingredients, val_labels)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, collate_fn = padder, shuffle=True)\n",
    "validation_loader_cuisine = DataLoader(dataset=validation_dataset_cuisine, batch_size=batch_size, collate_fn = padder)\n",
    "validation_loader_ingredients = DataLoader(dataset=validation_dataset_ingredients, batch_size=batch_size, collate_fn = padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "_VICOllFh2ls"
   },
   "outputs": [],
   "source": [
    "model = MiltitaskRecFormer(num_tokens, num_labels, dim_model, num_heads, num_encoder_layers, num_decoder_layers, dropout_p)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I1kXl1Hoh2ls",
    "outputId": "41847d69-e82a-4ee5-f0dd-90e83f0cf119"
   },
   "outputs": [],
   "source": [
    "train_multitask(model, criterion, optimizer, train_loader, validation_loader_cuisine, validation_loader_ingredients, epochs, loss_weights=[0.5, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), \"RecFormer_multitask.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7608, device='cuda:0')\n",
      "tensor(0.1244, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"weights/RecFormer_multitask.pth\"))\n",
    "model.to(device)\n",
    "print(measure_accuracy(model, validation_loader_cuisine, multitask_switch=\"cuisine\"))\n",
    "print(measure_accuracy(model, validation_loader_ingredients, multitask_switch=\"ingredients\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7848\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "classification_preds = []\n",
    "with torch.no_grad():\n",
    "    for batch in validation_loader_cuisine:\n",
    "        preds = predict_on_batch(model, batch, \"cuisine\")\n",
    "        target = batch[1].to(device=device).flatten()\n",
    "        classification_preds.extend(torch.argmax(preds, axis=1).tolist())\n",
    "print(len(classification_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_cus = {y: x for x, y in cusine_vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.70      0.61      0.65        85\n",
      "     british       0.47      0.43      0.45       161\n",
      "cajun_creole       0.76      0.66      0.71       295\n",
      "     chinese       0.78      0.85      0.81       516\n",
      "    filipino       0.71      0.60      0.65       141\n",
      "      french       0.55      0.62      0.58       538\n",
      "       greek       0.68      0.65      0.67       222\n",
      "      indian       0.85      0.88      0.86       624\n",
      "       irish       0.50      0.53      0.52       122\n",
      "     italian       0.83      0.84      0.83      1558\n",
      "    jamaican       0.69      0.61      0.65       113\n",
      "    japanese       0.80      0.65      0.71       290\n",
      "      korean       0.78      0.69      0.74       167\n",
      "     mexican       0.90      0.90      0.90      1273\n",
      "    moroccan       0.72      0.76      0.74       160\n",
      "     russian       0.55      0.51      0.53        92\n",
      " southern_us       0.69      0.74      0.71       839\n",
      "     spanish       0.51      0.39      0.44       189\n",
      "        thai       0.76      0.82      0.79       294\n",
      "  vietnamese       0.74      0.64      0.69       169\n",
      "\n",
      "    accuracy                           0.76      7848\n",
      "   macro avg       0.70      0.67      0.68      7848\n",
      "weighted avg       0.76      0.76      0.76      7848\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "\n",
    "print(classification_report([id_to_cus[id] for id in val_labels_c], [id_to_cus[id] for id in classification_preds]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gn4ox-NYh2lt"
   },
   "source": [
    "## Word embeddings multi-task experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip glove*.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "emb_length = 100\n",
    "glove_vocab = {}\n",
    "with open('glove.6B/glove.6B.{}d.txt'.format(emb_length), encoding='utf-8') as f:\n",
    "  for line in f:\n",
    "      values = line.split()\n",
    "      word = values[0]\n",
    "      coefs = np.asarray(values[1:], dtype='float32')\n",
    "      glove_vocab[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_embedding = torch.zeros(emb_length)\n",
    "UNK_embedding = np.mean(list(glove_vocab.values()), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6714\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_fwf('node_ingredient.csv', header=None)\n",
    "node_ingredient = df[0].values.tolist()\n",
    "print(len(node_ingredient))\n",
    "ing_id_to_str = {i: ing for i,ing in enumerate(node_ingredient)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "padder = Padder(dim=0, pad_symbol=PAD_embedding)\n",
    "\n",
    "train_dataset = EmbDataset(multitask_data, multitask_labels, glove_vocab, UNK_embedding, ing_id_to_str)\n",
    "validation_dataset_cuisine = EmbDataset(val_ingredients_c, val_labels_c, glove_vocab, UNK_embedding, ing_id_to_str)\n",
    "validation_dataset_ingredients = EmbDataset(val_ingredients, val_labels, glove_vocab, UNK_embedding, ing_id_to_str)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, collate_fn = padder, shuffle=True)\n",
    "validation_loader_cuisine = DataLoader(dataset=validation_dataset_cuisine, batch_size=batch_size, collate_fn = padder)\n",
    "validation_loader_ingredients = DataLoader(dataset=validation_dataset_ingredients, batch_size=batch_size, collate_fn = padder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MiltitaskRecFormer(num_tokens, num_labels, 100, num_heads, num_encoder_layers, num_decoder_layers, dropout_p, use_pretrained_embeddings=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_multitask(model, criterion, optimizer, train_loader, validation_loader_cuisine, validation_loader_ingredients, epochs, loss_weights=[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7598, device='cuda:0')\n",
      "tensor(0.1095, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "print(measure_accuracy(model, validation_loader_cuisine, multitask_switch=\"cuisine\"))\n",
    "print(measure_accuracy(model, validation_loader_ingredients, multitask_switch=\"ingredients\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "recipe_transformers.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
